{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kickstartin' Success\n",
    "\n",
    "By: Priscilla Mannuel, Mark Roberts\n",
    "\n",
    "In this study, we will explore [data](https://webrobots.io/kickstarter-datasets/) on craft beers.\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Initialization](#init)\n",
    "* [Analysis](#analysis)\n",
    "* [Conclusion](#conclud)\n",
    "\n",
    "<h4><center>...</center></h4>\n",
    "\n",
    "<a id='intro'><h2>Introduction</h2></a>\n",
    "\n",
    "...\n",
    "\n",
    "<h2><a id='intro'>Initialization</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "import os, json\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import ttest_ind, f_oneway, lognorm, levy, skew, chisquare\n",
    "from sklearn.preprocessing import normalize, scale\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset utilized is provided by [Kaggle](https://www.kaggle.com/nickhould/craft-cans). The dataset contains a list of 2K+ craft canned beers from the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download dataset\n",
    "# Check if the dataset is present on local disk and load it\n",
    "if os.path.exists('dataset/kaggle_beer.csv'):\n",
    "    data = pd.read_csv('dataset/kaggle_beer.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5973\n",
      "Number of columns: 22\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the dataset\n",
    "print (\"Number of rows:\", data.shape[0])\n",
    "print (\"Number of columns:\", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>id</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>style_id</th>\n",
       "      <th>Alcohol By Volume</th>\n",
       "      <th>International Bitterness Units</th>\n",
       "      <th>Standard Reference Method</th>\n",
       "      <th>Universal Product Code</th>\n",
       "      <th>filepath</th>\n",
       "      <th>...</th>\n",
       "      <th>last_mod</th>\n",
       "      <th>Style</th>\n",
       "      <th>Category</th>\n",
       "      <th>Brewer</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scottish Ale</td>\n",
       "      <td>1495</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-07-23T01:30:00+05:30</td>\n",
       "      <td>Scotch Ale</td>\n",
       "      <td>British Ale</td>\n",
       "      <td>Carlyle Brewing</td>\n",
       "      <td>215 East State Street</td>\n",
       "      <td>Rockford</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.2689, -89.0907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Het Kapittel Pater</td>\n",
       "      <td>1509</td>\n",
       "      <td>301</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-07-23T01:30:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brouwerij Van Eecke</td>\n",
       "      <td>Douvieweg 2</td>\n",
       "      <td>Watou</td>\n",
       "      <td>West-Vlaanderen</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>50.8612, 2.6615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Export Premium</td>\n",
       "      <td>1516</td>\n",
       "      <td>785</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-07-23T01:30:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Licher Privatbrauerei</td>\n",
       "      <td>In den Hardtberggrten</td>\n",
       "      <td>Lich</td>\n",
       "      <td>Hessen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.5208, 8.8166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bee Sting Honey Ale</td>\n",
       "      <td>1527</td>\n",
       "      <td>604</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-07-23T01:30:00+05:30</td>\n",
       "      <td>American-Style Pale Ale</td>\n",
       "      <td>North American Ale</td>\n",
       "      <td>Great Divide Brewing</td>\n",
       "      <td>2201 Arapahoe Street</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.7539, -104.989</td>\n",
       "      <td>http://www.greatdivide.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PranQster Belgian Ale</td>\n",
       "      <td>1540</td>\n",
       "      <td>919</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-07-23T01:30:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Coast Brewing Company</td>\n",
       "      <td>455 North Main Street</td>\n",
       "      <td>Fort Bragg</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.4466, -123.806</td>\n",
       "      <td>http://www.northcoastbrewing.com/home.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name    id brewery_id cat_id style_id  Alcohol By Volume  \\\n",
       "0           Scottish Ale  1495        347      1       15                5.8   \n",
       "1     Het Kapittel Pater  1509        301     -1       -1                0.0   \n",
       "2         Export Premium  1516        785     -1       -1                5.4   \n",
       "3    Bee Sting Honey Ale  1527        604      3       26                5.9   \n",
       "4  PranQster Belgian Ale  1540        919     -1       -1                7.6   \n",
       "\n",
       "   International Bitterness Units  Standard Reference Method  \\\n",
       "0                             0.0                        0.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             0.0                        0.0   \n",
       "3                             0.0                        0.0   \n",
       "4                             0.0                        0.0   \n",
       "\n",
       "   Universal Product Code filepath                    ...                      \\\n",
       "0                     0.0      NaN                    ...                       \n",
       "1                     0.0      NaN                    ...                       \n",
       "2                     0.0      NaN                    ...                       \n",
       "3                     0.0      NaN                    ...                       \n",
       "4                     0.0      NaN                    ...                       \n",
       "\n",
       "                    last_mod                    Style            Category  \\\n",
       "0  2010-07-23T01:30:00+05:30               Scotch Ale         British Ale   \n",
       "1  2010-07-23T01:30:00+05:30                      NaN                 NaN   \n",
       "2  2010-07-23T01:30:00+05:30                      NaN                 NaN   \n",
       "3  2010-07-23T01:30:00+05:30  American-Style Pale Ale  North American Ale   \n",
       "4  2010-07-23T01:30:00+05:30                      NaN                 NaN   \n",
       "\n",
       "                        Brewer                Address        City  \\\n",
       "0              Carlyle Brewing  215 East State Street    Rockford   \n",
       "1          Brouwerij Van Eecke            Douvieweg 2       Watou   \n",
       "2        Licher Privatbrauerei  In den Hardtberggrten        Lich   \n",
       "3         Great Divide Brewing   2201 Arapahoe Street      Denver   \n",
       "4  North Coast Brewing Company  455 North Main Street  Fort Bragg   \n",
       "\n",
       "             State        Country        Coordinates  \\\n",
       "0         Illinois  United States  42.2689, -89.0907   \n",
       "1  West-Vlaanderen        Belgium    50.8612, 2.6615   \n",
       "2           Hessen        Germany    50.5208, 8.8166   \n",
       "3         Colorado  United States  39.7539, -104.989   \n",
       "4       California  United States  39.4466, -123.806   \n",
       "\n",
       "                                     Website  \n",
       "0                                        NaN  \n",
       "1                                        NaN  \n",
       "2                                        NaN  \n",
       "3                http://www.greatdivide.com/  \n",
       "4  http://www.northcoastbrewing.com/home.htm  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Quick Data Overview</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "il_beers_only = data[data.State == 'Illinois']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 190\n",
      "Number of columns: 22\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of rows:\", il_beers_only.shape[0])\n",
    "print (\"Number of columns:\", il_beers_only.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'id', 'brewery_id', 'cat_id', 'style_id', 'Alcohol By Volume',\n",
       "       'International Bitterness Units', 'Standard Reference Method',\n",
       "       'Universal Product Code', 'filepath', 'Description', 'add_user',\n",
       "       'last_mod', 'Style', 'Category', 'Brewer', 'Address', 'City', 'State',\n",
       "       'Country', 'Coordinates', 'Website'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                               0.167420\n",
       "id                                 0.000000\n",
       "brewery_id                         0.167420\n",
       "cat_id                             0.385066\n",
       "style_id                           0.401808\n",
       "Alcohol By Volume                  0.418550\n",
       "International Bitterness Units     0.418550\n",
       "Standard Reference Method          0.418550\n",
       "Universal Product Code             0.485518\n",
       "filepath                          99.581450\n",
       "Description                       65.745856\n",
       "add_user                           0.719906\n",
       "last_mod                           1.222166\n",
       "Style                             25.230203\n",
       "Category                          25.230203\n",
       "Brewer                             0.418550\n",
       "Address                           13.092248\n",
       "City                               0.870584\n",
       "State                              5.842960\n",
       "Country                            0.418550\n",
       "Coordinates                        3.800435\n",
       "Website                           51.799766\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() / 5973 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='analysis'>Analysis</a></h2>\n",
    "\n",
    "**Summary**\n",
    "\n",
    "The initial dataset contained 5973 variations of canned craft beers. In order to build the business case, the analysis process is brokened down into (1) [Data cleaning](#s1), (2) [Feature engineering](#s2) (3) [Exploratory data analysis](#s3) and (4) [Visualization](#s4).\n",
    "\n",
    "<h3><a id='s1'>Data Cleaning</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to clean a loaded dataset\n",
    "\n",
    "def clean(mydata):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function cleans the input dataframe mydata:\n",
    "    \n",
    "    input:\n",
    "        mydata: pandas.dataframe\n",
    "    output: \n",
    "        pandas.dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data = mydata.copy()\n",
    "    \n",
    "    #get rid of uneccessary columns in training and testing\n",
    "    selected_cols = ['filepath',\n",
    "                     'blurb',]\n",
    "    \n",
    "    data = data[selected_cols]\n",
    "\n",
    "    #drop data with empty blurb or empty name entries\n",
    "    #given more time, webscrapped missing entries\n",
    "    data = data.dropna() \n",
    "\n",
    "    #select only data with known status\n",
    "    successful = data['state'] == \"successful\"\n",
    "    failed = data['state'] == \"failed\"\n",
    "    cancelled = data['state'] == \"cancelled\"\n",
    "    suspended = data['state'] == \"suspended\"\n",
    "    data = data.loc[failed | successful | cancelled | suspended]\n",
    "\n",
    "    #label categorical collumns                   ##Commented by NN\n",
    "    #categorical_cols = ['category.id',\n",
    "    #                    'category.parent_id',\n",
    "    #                    'country',\n",
    "    #                    'spotlight',\n",
    "    #                    'staff_pick',\n",
    "    #                    'state',\n",
    "    #                    'usd_type']\n",
    "    #data[categorical_cols] = pd.Categorical\n",
    "\n",
    "    #label numerical collumns\n",
    "    num_cols = ['usd_pledged',\n",
    "                'deadline',\n",
    "                'created_at',\n",
    "                'launched_at']\n",
    "    data[num_cols] = data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    #because there are some \"bad lines\" a.k.a lines that are shifted to the right due to bad parsing\n",
    "    #subset rows that are correctly parsed\n",
    "    data = data.dropna()\n",
    "\n",
    "    #label datetime collumns\n",
    "    data['created_at'] = pd.to_datetime(data['created_at'],unit='s')\n",
    "    data['launched_at'] = pd.to_datetime(data['launched_at'],unit='s')\n",
    "    data['deadline'] = pd.to_datetime(data['deadline'],unit='s')    ## Corrected the variable\n",
    "    \n",
    "    #CORRECT RANGE\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's clean the data... *scrub* *scrub* *scrub* **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Data dim before cleaning:\", data.shape)\n",
    "data = clean(data)\n",
    "print(\"Data dim after cleaning:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[data.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id='s3'>Feature Engineering</a></h3>\n",
    "\n",
    "In order to gain a deeper understanding of Kickstarter environment and the drivers to successful campaigns, new features are intuitively engineered from current variables. The end results reduced the dataset to the following features:\n",
    "\n",
    "* **success**: boolean feature indicating campaign (1) success (0) failure\n",
    "* **name_len**: length of name of project\n",
    "* **desc_len**: length of the short description or blurb\n",
    "* **state**: successful, failed, cancelled, or suspended\n",
    "* **duration**: days between creation and launch of campaign\n",
    "* **time variables**: month, wday (day of week), hour (hour of day)\n",
    "* **category**:\n",
    "* **subcategory**:\n",
    "* **country**:\n",
    "* **spotlight**:\n",
    "* **staff_picked**:\n",
    "* **goal**:\n",
    "* pics_count:\n",
    "\n",
    "Additionally, these features can be included to predict campaigns that have already started:\n",
    "\n",
    "* comments: the number of comments\n",
    "* **traction**: rate of gaining backers, total number of backers divided by total number of weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def engineer_features(mydata):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function generates new features for the input dataframe mydata:\n",
    "    \n",
    "    input:\n",
    "        mydata: pandas.dataframe\n",
    "    output: \n",
    "        pandas.dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data = mydata.copy()\n",
    "\n",
    "    # create success variable (PREDICT)\n",
    "    #data['success'] = data['state'].astype('category')\n",
    "    #data['success'] = pd.Categorical.from_array(data.success).codes\n",
    "    \n",
    "    #data = data.drop(drop_cols, axis = 1)\n",
    "    data['state'].replace('suspended','failed',inplace=True)\n",
    "    \n",
    "    #Categories is initially a json datatype that would need to be deserialized to the Python native datatype of dictionary.\n",
    "    data['catg.type'], data['catg.subtype'] = data['category.slug'].str.split('/', 1).str\n",
    "    \n",
    "    data['state_num'] = data['state'].apply(lambda x: 1 if x=='successful' else 0)\n",
    "    \n",
    "    data['launched_at_hr'] = data['launched_at'].apply(lambda x: x.hour) + 1\n",
    "    data['launched_at_dow'] = data['launched_at'].apply(lambda x: x.dayofweek + 1) #Monday=1, Sunday=7\n",
    "    data['launched_at_mo'] = data['launched_at'].apply(lambda x: x.month)\n",
    "    data['launched_at_yr'] = data['launched_at'].apply(lambda x: x.year)\n",
    "    \n",
    "    data['deadline_hr'] = data['deadline'].apply(lambda x: x.hour) + 1\n",
    "    data['deadline_dow'] = data['deadline'].apply(lambda x: x.dayofweek + 1) #Monday=1, Sunday=7\n",
    "    data['deadline_mo'] = data['deadline'].apply(lambda x: x.month)\n",
    "    data['deadline_yr'] = data['deadline'].apply(lambda x: x.year)\n",
    "    \n",
    "    data['created_at_hr'] = data['created_at'].apply(lambda x: x.hour) + 1\n",
    "    data['created_at_dow'] = data['created_at'].apply(lambda x: x.dayofweek + 1) #Monday=1, Sunday=7\n",
    "    data['created_at_mo'] = data['created_at'].apply(lambda x: x.month)\n",
    "    data['created_at_yr'] = data['created_at'].apply(lambda x: x.year)\n",
    "    \n",
    "    #To plot the number of campaigns per month for all years\n",
    "    data['count'] = 1\n",
    "    \n",
    "    data['success'] = (data['state'] == 'successful')\n",
    "    \n",
    "    #State_changed_at is column describing when the campaign changed state to either successful, failed, cancelled or suspended. \n",
    "    #Since this will not be known ahead of time for a given campaign, this is not a good datetime to use in the following \n",
    "    #look at the time differences between our dates.\n",
    "    #creation and launch\n",
    "    #launch and deadline\n",
    "    data['launched-created'] = (data.launched_at - data.created_at).dt.components.days\n",
    "    data['deadline-launched'] = (data.deadline - data.launched_at).dt.components.days\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's engineer new features!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data dim before feature engineering:\", data.shape)\n",
    "data = engineer_features(data)\n",
    "print(\"Data dim after feature engineering:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make spotlight into boolean\n",
    "# spotlightmap = {True: True, False: False, 'True': True, 'False': False}\n",
    "\n",
    "# data['spotlight'] = data['spotlight'].map(spotlightmap)\n",
    "\n",
    "data['spotlight'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3><a id=''>Sanity Check</a></h3>\n",
    "<br>\n",
    "\n",
    "\n",
    "State_changed_at is column describing when the campaign changed state to either successful, failed, cancelled or suspended. Since this will not be known ahead of time for a given campaign, this is not a good datetime to use in the following look at the time differences between our dates.\n",
    "\n",
    "* creation and launch\n",
    "* launch and deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(data['goal'], 10).value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['catg.type'].value_counts().plot.pie(autopct='%.2f',figsize=(6,6))\n",
    "plt.title('Distribution of projects in different categories')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple quality check: Let's check to make sure no launch dates came after before deadline dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(data.deadline < data.launched_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.launched_at_yr.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot will look at counts in campaigns from 2009 to 2018 grouped by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_campaign_count(n):\n",
    "    \n",
    "    mth = data[data['launched_at_yr'] == n]\n",
    "    mth_cnt = mth.groupby('launched_at_mo').count()['count']\n",
    "    mth_cnt.plot(marker='o', markersize=5, alpha=.5, rot=90)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "for i in range(2009, 2019):\n",
    "    plot_monthly_campaign_count(i)\n",
    "plt.ylabel('Number of Campaigns', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.legend(range(2009, 2018))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak campaign count occured in the month of july in 2014. I wonder what caused that? Not really any seasonality is readily apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data.launched_at_mo, data.launched_at_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.staff_pick.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.staff_pick.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe discrepancy in values and correct it to only reflect True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.replace({'staff_pick': {'True': True, 'False': False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.staff_pick.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "staff_picked = data.staff_pick.value_counts()\n",
    "print(\"Not so nice, ~ %g%% are staff picked\" % (staff_picked[1] * 100 / staff_picked.sum()).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['success'] = (data['state'] == 'successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.success.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State_changed_at is column describing when the campaign changed state to either successful, failed, cancelled or suspended. Since this will not be known ahead of time for a given campaign, this is not a good datetime to use in the following look at the time differences between our dates.\n",
    "\n",
    "* creation and launch\n",
    "* launch and deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['launched-created'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['deadline-launched'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id='s1'>Exploratory Data Analysis</a></h3>\n",
    "<br>\n",
    "<center>**Unsupervised learning**</center>\n",
    "\n",
    "In order to narrow our exploration. We studied the correlation and utilized clustering to investigate latent drivers that contribute to the success of a campaign.\n",
    "\n",
    "<h4><center>...</center></h4>\n",
    "\n",
    "**Target Variable: Success** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state'].value_counts().plot.pie(autopct='%.2f')\n",
    "plt.title('Distribution of successful (1)/failed (0) projects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(data.groupby(['state']).size())\n",
    "stats['Project proportion(%)'] = round((data.groupby(['state']).size()/sum(data.groupby(['state']).size()))*100,2)\n",
    "stats['Project median goal($)'] = round((data.groupby(['state'])['goal'].median()),2).astype(str)\n",
    "stats['Project average goal($)'] = round(data.groupby(['state'])['goal'].mean(),2)\n",
    "stats['Median Pledged($)'] = round((data.groupby(['state'])['usd_pledged'].median()),2).astype(str)\n",
    "stats['Average pledged($)'] = round(data.groupby(['state'])['usd_pledged'].mean(),2)\n",
    "stats['Max. Backers Count'] = data.groupby(['state'])['backers_count'].max()\n",
    "stats.columns.values[0]='Projects'\n",
    "\n",
    "stats.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation matrix** <br>\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam ultrices nisl odio, non fringilla lorem lacinia et. Cras in nibh diam. Donec bibendum eros nulla, et aliquam nunc ultricies in. Nulla ut lacinia justo. Donec sit amet efficitur nisl, sed porta odio. Donec et blandit augue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "def corrmatrix(mydata,annot=True):\n",
    "        \n",
    "    \"\"\"\n",
    "    This function cleans the input dataframe mydata:\n",
    "    \n",
    "    input:\n",
    "        mydata: pandas.dataframe\n",
    "    output: \n",
    "        pandas.dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data = mydata.copy()\n",
    "    \n",
    "    data_continuos = data.select_dtypes(include=['int64','float64'])\n",
    "    \n",
    "    continuous_variables = list(data_continuos)\n",
    "    \n",
    "    corr = data_continuos.corr()\n",
    "    \n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    with sns.axes_style(\"white\"):\n",
    "        ax = sns.heatmap(corr, mask=mask, annot=annot, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['category.id',\n",
    "                'category.parent_id',\n",
    "                'state_num',\n",
    "                'launched_at_hr',\n",
    "                'launched_at_dow',\n",
    "                'launched_at_mo',\n",
    "                'launched_at_yr',\n",
    "                'deadline_hr',\n",
    "                'deadline_dow',\n",
    "                'deadline_mo',\n",
    "                'deadline_yr',\n",
    "                'created_at_hr',\n",
    "                'created_at_dow',\n",
    "                'created_at_mo',\n",
    "                'created_at_yr',\n",
    "                'count']\n",
    "\n",
    "corrmatrix(data.drop(dropped_cols, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.drop(dropped_cols, axis=1).select_dtypes(include=['int64','float64']), palette=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Means clustering** <br>\n",
    "<br>\n",
    "K-means clustering is one of the most widely used unsupervised machine learning algorithms that forms clusters of data based on the similarity between data instances. For this particular algorithm to work, the number of clusters has to be defined beforehand. The K in the K-means refers to the number of clusters.\n",
    "\n",
    "1. Import kmeans and PCA through the sklearn library\n",
    "2. Devise an elbow curve to select the optimal number of clusters (k)\n",
    "3. Generate and visualise a k-means clusters\n",
    "\n",
    "We need to determine optimal k.The technique to determine K, the number of clusters, is called the elbow method.\n",
    "\n",
    "We plot values for K on the horizontal axis and the distortion on the Y axis (the values calculated with the cost function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datac=data.copy()\n",
    "selected_cols=['backers_count','goal','usd_pledged']\n",
    "datac=datac[selected_cols]\n",
    "\n",
    "\n",
    "# scaling the data \n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "datac = pd.DataFrame(scale(datac), columns=['backers_count','goal','usd_pledged'])\n",
    "\n",
    "# k means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# first step is to determine k\n",
    "distortions = []\n",
    "score=[]\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(datac)\n",
    "    kmeanModel.fit(datac)\n",
    "    distortions.append(sum(np.min(cdist(datac, kmeanModel.cluster_centers_,\n",
    "                                        'euclidean'),axis=1)) / datac.shape[0])\n",
    "    score.append(kmeanModel.fit(datac).score(datac) )\n",
    "\n",
    "\n",
    "#Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot centroids and clusters\n",
    "from sklearn import cluster\n",
    "centroids,labels,inertia = cluster.k_means(datac,n_clusters=5)\n",
    "#Let's check the parameter cluster centers of the estimator\n",
    "\n",
    "centroids = pd.DataFrame(centroids,\n",
    "                         columns=['backers_count','goal','usd_pledged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(centroids, cmap='BuPu', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Understading the marketplace**</center>\n",
    "\n",
    "Throughout exploratory analysis, key understandings of Kickstarter marketplace is built.\n",
    "\n",
    "<h4><center>...</center></h4>\n",
    "\n",
    "**Kickstarter is predominantly domestic** <br>\n",
    "\n",
    "\n",
    "Although the platform boast its global reach, 79.7% of Kickstarter's campaign creators are United States-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autopct(pct):\n",
    "    return ('%.2f' % pct) if pct > 2 else ''\n",
    "\n",
    "labels = ['US', 'GB', 'CA'] + [\"\" for x in range(19)]\n",
    "\n",
    "data['country'].value_counts().plot.pie(autopct=my_autopct,labels=labels,figsize=(6,6))\n",
    "plt.title('Distribution of projects by countries')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kickstarter is home to the artsy-fartsy and the tech-enthusiast**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['catg.type'].value_counts().plot(kind = 'bar', title = 'Category Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x='catg.type', y='state_num', kind='bar', data=data, size=6)\n",
    "locs, labels = plt.xticks();\n",
    "plt.title('Percentage of successful projects per category')\n",
    "plt.setp(labels, rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation of campaigns varies by time** <br>\n",
    "<br>\n",
    "The timeline of a Kickstarter campaign includes creation of the campaign where creators set up the funding page and marketing material, launching the campaign where creators publish the campaign for others to start backing. Creation and launching is more popular during the weekday (Monday - Friday) between 4 PM - 4 AM. The timing of campaign creation and launch all coincide with the average work-hours, suggesting that people create Kickstarter campaigns during the\n",
    "workday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_monthly_campaign_count(n):\n",
    "    mth = data[data['launched_at_yr'] == n]\n",
    "    mth_cnt = mth.groupby('launched_at_mo').count()['count']\n",
    "    mth_cnt.plot(marker='o', markersize=5, alpha=.5, rot=90)\n",
    "\n",
    "# Project creation density by dow and hr\n",
    "c_dow_vs_hr = pd.core.frame.DataFrame({'count' : data.groupby(['created_at_dow','created_at_hr']).size()}).reset_index()\n",
    "c_dow_vs_hr['created_at_dow'] = c_dow_vs_hr['created_at_dow'].astype('category')\n",
    "c_dow_vs_hr = c_dow_vs_hr.pivot(\"created_at_dow\", \"created_at_hr\", \"count\")\n",
    "\n",
    "# Project launched density by dow and hr\n",
    "l_dow_vs_hr = pd.core.frame.DataFrame({'count' : data.groupby(['launched_at_dow','launched_at_hr']).size()}).reset_index()\n",
    "l_dow_vs_hr['launched_at_dow'] = l_dow_vs_hr['launched_at_dow'].astype('category')\n",
    "l_dow_vs_hr = l_dow_vs_hr.pivot(\"launched_at_dow\", \"launched_at_hr\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n",
    "fig.subplots_adjust(hspace=0, wspace = 0.2)\n",
    "\n",
    "sns.heatmap(c_dow_vs_hr, ax=axes[0], cmap='BuPu')\n",
    "sns.heatmap(l_dow_vs_hr, ax=axes[1], cmap='BuPu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15,15))\n",
    "fig.subplots_adjust(hspace=0.5, wspace = 0.3)\n",
    "\n",
    "sns.countplot(x=\"launched_at_hr\", hue=\"success\", data=data, ax=axes[0, 0]).set_title('Launched at Hour Distribution')\n",
    "sns.countplot(x=\"created_at_hr\", hue=\"success\", data=data, ax=axes[1, 0]).set_title('Created at Hour Distribution')\n",
    "sns.countplot(x=\"deadline_hr\", hue=\"success\", data=data, ax=axes[2, 0]).set_title('Deadline Hour Distribution')\n",
    "sns.countplot(x=\"launched_at_dow\", hue=\"success\", data=data, ax=axes[0, 1]).set_title('Launched at weekday Distribution')\n",
    "sns.countplot(x=\"created_at_dow\", hue=\"success\", data=data, ax=axes[1, 1]).set_title('Created at weekday Distribution')\n",
    "sns.countplot(x=\"deadline_dow\", hue=\"success\", data=data, ax=axes[2, 1]).set_title('Deadline weekday Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Finding insights that matter</center>\n",
    "    \n",
    "After a establishing understanding of the Kickstarter nature of campaign creators, drivers that promotes success are  determined. Potential features are studied and a t-test is performed to determine whether the feature can be used to significantly distinguish successful campaigns from failed ones.\n",
    "\n",
    "<h4><center>...</center></h4>\n",
    "\n",
    "**Setting the right goal is as important as you'd think** <br>\n",
    "The median goal for a successful campaign from the dataset is USD 5,000 while the medial goal for failed campaigns is nearly USD 17,000. We also found that 38% of failed campaigns had a goal of over USD 50,000. From the comparison below, per main category, there is a clear separation of range of goals ($) between successful and failed cases. The successful cases have way lower/achievable goal compared to the failed cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x='catg.type', y='goal', hue='state_num', kind='bar', data=data, size=7)\n",
    "locs, labels = plt.xticks();\n",
    "plt.setp(labels, rotation=90);\n",
    "plt.title('Range of goal ($) among successful and failed projects')\n",
    "plt.gca().set_yscale(\"log\", nonposy='clip');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_success = data[(data['state_num'] == 1)]\n",
    "\n",
    "df_success = np.sort(df_success.goal).cumsum()\n",
    "\n",
    "# Percentile values\n",
    "p = np.array([0.0, 25.0, 50.0, 75.0, 90.0, 100.0])\n",
    "\n",
    "perc_success = mlab.prctile(df_success, p=p)\n",
    "\n",
    "plt.plot(df_success, color='green')\n",
    "plt.title(\"Proportion of Successful Campaigns by Goal\")\n",
    "plt.ylabel('Goal (USD)')\n",
    "plt.xlabel('Percentage of Campaigns (%)')\n",
    "\n",
    "# Set tick locations and labels\n",
    "plt.xticks((len(df_success)-1) * p/100., map(str, p))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_fail = data[(data['state_num'] == 0)]\n",
    "\n",
    "df_fail = np.sort(df_fail.goal).cumsum()\n",
    "\n",
    "# Percentile values\n",
    "p = np.array([0.0, 25.0, 50.0, 75.0, 90.0, 100.0])\n",
    "\n",
    "perc_fail = mlab.prctile(df_fail, p=p)\n",
    "\n",
    "plt.plot(df_fail, color='darkred')\n",
    "plt.title(\"Proportion of Failed Campaigns by Goal\")\n",
    "plt.ylabel('Goal (USD)')\n",
    "plt.xlabel('Percentage of Campaigns (%)')\n",
    "plt.gca().set_ylim(0,8e8)\n",
    "\n",
    "# Set tick locations and labels\n",
    "plt.xticks((len(df_fail)-1) * p/100., map(str, p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Staff picks have significant impact on success**<br>\n",
    "<br>\n",
    "Kickstarter’s “staff picks” are given high-value front page real estate as “ Projects We Love” . Since these projects are given such high visibility, it’s no surprise that staff pick projects are 9.6 times more likely to be successful than those that aren’t. While it’s understandable that not all projects can be staff picks, we will touch on how Kickstarter can leverage the power of staff picks to improve its platform’s success rate in the implications section.\n",
    "\n",
    "Staff picks are another variable of interest we are interested in determining. I can perform the same sort of analysis I will make in this notebook to staff picks. We would be interested in finding which features are associated with higher probabilities of Kickstarter staff choosing a campaign to tag with the staff pick criteria. This seems to boost backer confidence and is associated with a higher probability of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n",
    "fig.subplots_adjust(hspace=0, wspace = 0.5)\n",
    "\n",
    "sns.countplot(x=\"staff_pick\", hue=\"success\", ax=axes[0], data=data).set_title('Staff Picked Distribution')\n",
    "sns.countplot(x=\"spotlight\", hue=\"success\", ax=axes[1], data=data).set_title('Spotlight Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff_picked = data.staff_pick.value_counts()\n",
    "\n",
    "print(\"Not so nice, ~ %g%% are staff picked\" % (staff_picked[1] * 100 / staff_picked.sum()).round())\n",
    "\n",
    "pd.crosstab(data.staff_pick, data.success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Successful campaigns invest more time in creating the campaign.** <br>\n",
    "<br>\n",
    "The median number of days spent between creation and launch for successful campaigns is 19, as compared to the median of 12 days spent for failed  campaigns. Furthermore, taking longer than 1 week to create your campaign makes your campaign 1.83 times more likely to succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot('launched-created', by='success')\n",
    "plt.ylim(-1,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tripdist_quant <- quantile(df$Trip_distance, seq(0,1,0.01))\n",
    "tripdist_quant <- data.frame(fval=seq(0,1,0.01), q=tripdist_quant, row.names=NULL)\n",
    "\n",
    "xyplot(q ~ fval, \n",
    "       tripdist_quant,\n",
    "       xlab = \"Proportion\", \n",
    "       ylab = \"Trip Distance (miles)\",\n",
    "       type = c(\"p\", \"g\"), \n",
    "       subset = q < 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_success = data[(data['state_num'] == 1)]\n",
    "\n",
    "d = np.sort(df_success['launched-created']).cumsum()\n",
    "\n",
    "# Percentile values\n",
    "p = np.array([0.0, 25.0, 50.0, 75.0, 90.0, 100.0])\n",
    "\n",
    "perc = mlab.prctile(d, p=p)\n",
    "\n",
    "plt.plot(d, color='green')\n",
    "plt.title(\"Proportion of Successful Campaigns by launched-creation duration\")\n",
    "plt.ylabel('Duration (mins)')\n",
    "plt.xlabel('Percentage of Campaigns (%)')\n",
    "\n",
    "# Set tick locations and labels\n",
    "plt.xticks((len(d)-1) * p/100., map(str, p))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_fail = data[(data['state_num'] == 0)]\n",
    "\n",
    "d = np.sort(df_fail['launched-created']).cumsum()\n",
    "\n",
    "# Percentile values\n",
    "p = np.array([0.0, 25.0, 50.0, 75.0, 90.0, 100.0])\n",
    "\n",
    "perc = mlab.prctile(d, p=p)\n",
    "\n",
    "plt.plot(d, color='darkred')\n",
    "plt.title(\"Proportion of Failed Campaigns by launched-creation duration\")\n",
    "plt.ylabel('Duration (mins)')\n",
    "plt.xlabel('Percentage of Campaigns (%)')\n",
    "plt.gca().set_ylim(0,3500000)\n",
    "\n",
    "# Set tick locations and labels\n",
    "plt.xticks((len(d)-1) * p/100., map(str, p))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
